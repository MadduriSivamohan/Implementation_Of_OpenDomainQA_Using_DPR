{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e64e6ad-2cdb-4d39-913e-ab68b467f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define a simple dataset class\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, questions, passages, tokenizer, max_length=128):\n",
    "        self.questions = questions\n",
    "        self.passages = passages\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        passage = self.passages[idx]\n",
    "        question_enc = self.tokenizer(question, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        passage_enc = self.tokenizer(passage, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return question_enc['input_ids'].squeeze(), question_enc['attention_mask'].squeeze(), passage_enc['input_ids'].squeeze(), passage_enc['attention_mask'].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593c0147-6547-481c-b894-56bfe6e879d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualEncoderModel(torch.nn.Module):\n",
    "    def __init__(self, question_encoder, passage_encoder):\n",
    "        super(DualEncoderModel, self).__init__()\n",
    "        self.question_encoder = question_encoder\n",
    "        self.passage_encoder = passage_encoder\n",
    "\n",
    "    def forward(self, question_ids, question_mask, passage_ids, passage_mask):\n",
    "        question_outputs = self.question_encoder(input_ids=question_ids, attention_mask=question_mask)\n",
    "        passage_outputs = self.passage_encoder(input_ids=passage_ids, attention_mask=passage_mask)\n",
    "        \n",
    "        # Pooling the output embeddings of the [CLS] token\n",
    "        question_pooler_output = question_outputs.pooler_output\n",
    "        passage_pooler_output = passage_outputs.pooler_output\n",
    "        return question_pooler_output, passage_pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcfa7154-cef2-4bc9-97c3-8e0991cade1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(anchor, positive, negative, margin=1.0):\n",
    "    distance_positive = F.cosine_similarity(anchor, positive)\n",
    "    distance_negative = F.cosine_similarity(anchor, negative)\n",
    "    loss_values = torch.relu(distance_positive - distance_negative + margin)\n",
    "    loss = torch.mean(loss_values)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da49712e-f16d-4221-83f5-ce8ba940afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Initialize two BERT models\n",
    "question_encoder = BertModel.from_pretrained(model_name)\n",
    "passage_encoder = BertModel.from_pretrained(model_name)\n",
    "model = DualEncoderModel(question_encoder, passage_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb471823-a4e0-4da0-b49c-44b6eb4486a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"archive2/nq_small.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b52609-1d9b-43aa-a32c-d54284876c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1 kilohertz is equal to how many hertz?',\n",
       "       'How big is a 1 18 scale model?',\n",
       "       'When did christianity become official religion of rome?',\n",
       "       'When did salt and pepper became a pair?',\n",
       "       'Who was president when world war 2 ended?'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions=df[\"question\"].values\n",
    "passages=df[\"context\"].values\n",
    "questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a99c0ef-ed4c-4b08-9970-dad0e6ab616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.2694773841841535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5:  88%|██████████████████████████████████████████████▋      | 4695/5329 [4:01:30<37:12,  3.52s/it, loss=0.122]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "# questions = [\"What is the capital of France?\", \"Who wrote Romeo and Juliet?\"]\n",
    "# passages = [\"Paris is the capital of France.\", \"William Shakespeare wrote Romeo and Juliet.\"]\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = QADataset(questions, passages, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "margin = 0.5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False)\n",
    "\n",
    "    for question_ids, question_mask, passage_ids, passage_mask in progress_bar:\n",
    "        question_ids, question_mask = question_ids, question_mask\n",
    "        passage_ids, passage_mask = passage_ids, passage_mask\n",
    "\n",
    "        question_embeddings, passage_embeddings = model(question_ids, question_mask, passage_ids, passage_mask)\n",
    "        negative_embeddings = torch.roll(passage_embeddings, 1, dims=0)\n",
    "\n",
    "        loss = triplet_loss(question_embeddings, passage_embeddings, negative_embeddings, margin)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        progress_bar.set_postfix({'loss': total_loss / len(progress_bar)})\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ad19a3-cea0-49d1-8489-64fa9148a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths for saving the model\n",
    "model_path = 'dual_encoder_model.pth'\n",
    "\n",
    "# Save the model's state dictionary along with any necessary metadata\n",
    "torch.save({\n",
    "    'question_encoder_state_dict': model.question_encoder.state_dict(),\n",
    "    'passage_encoder_state_dict': model.passage_encoder.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    # Add any other relevant information such as tokenizer, hyperparameters, etc.\n",
    "}, model_path)\n",
    "\n",
    "print(f\"Model saved to '{model_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdadb49b-2685-43c1-87d1-9493f58219d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
